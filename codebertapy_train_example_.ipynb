{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os \n",
    "from tqdm import tqdm \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import random\n",
    "import time \n",
    "import datetime\n",
    "from transformers import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"sample_train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder = 'code'\n",
    "problem_folders = os.listdir(code_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:09<00:00, 32.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_script(script):\n",
    "    '''\n",
    "    간단한 전처리 함수\n",
    "    주석 -> 삭제\n",
    "    '    '-> tab 변환\n",
    "    다중 개행 -> 한 번으로 변환\n",
    "    '''\n",
    "    with open(script,'r',encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        preproc_lines = []\n",
    "        for line in lines:\n",
    "            if line.lstrip().startswith('#'):\n",
    "                continue\n",
    "            line = line.rstrip()\n",
    "            if '#' in line:\n",
    "                line = line[:line.index('#')]\n",
    "            line = line.replace('\\n','')\n",
    "            line = line.replace('    ','\\t')\n",
    "            if line == '':\n",
    "                continue\n",
    "            preproc_lines.append(line)\n",
    "        preprocessed_script = '\\n'.join(preproc_lines)\n",
    "    return preprocessed_script\n",
    "\n",
    "preproc_scripts = []\n",
    "problem_nums = []\n",
    "\n",
    "for problem_folder in tqdm(problem_folders):\n",
    "    scripts = os.listdir(os.path.join(code_folder,problem_folder))\n",
    "    problem_num = scripts[0].split('_')[0]\n",
    "    for script in scripts:\n",
    "        script_file = os.path.join(code_folder,problem_folder,script)\n",
    "        preprocessed_script = preprocess_script(script_file)\n",
    "\n",
    "        preproc_scripts.append(preprocessed_script)\n",
    "    problem_nums.extend([problem_num]*len(scripts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data = {'code':preproc_scripts, 'problem_num':problem_nums})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>problem_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45091</th>\n",
       "      <td>N=int(input())\\nS=input()\\nans=\"\"\\nfor i in ra...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45092</th>\n",
       "      <td>N = int(input())\\nS = str(input())\\nalpha = ['...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45093</th>\n",
       "      <td>N = int(input())\\nS = input()\\nchar = ''\\nfor ...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45094</th>\n",
       "      <td>N = int(input())\\nS = input()\\nret = ''\\nfor s...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45095</th>\n",
       "      <td>N = int(input())\\nS = input()\\nanswer = []\\nfo...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45096</th>\n",
       "      <td>n = int(input())\\nS = input()\\na = ord('A')\\nz...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45097</th>\n",
       "      <td>alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\\nn = i...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45098</th>\n",
       "      <td>N = int(input())\\nS = input()\\nres = ''\\nfor c...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45099</th>\n",
       "      <td>import sys, bisect, math, itertools, string, q...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100</th>\n",
       "      <td>n = int(input())\\ns = input()\\nans = ''\\nfor i...</td>\n",
       "      <td>problem271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    code problem_num\n",
       "45091  N=int(input())\\nS=input()\\nans=\"\"\\nfor i in ra...  problem271\n",
       "45092  N = int(input())\\nS = str(input())\\nalpha = ['...  problem271\n",
       "45093  N = int(input())\\nS = input()\\nchar = ''\\nfor ...  problem271\n",
       "45094  N = int(input())\\nS = input()\\nret = ''\\nfor s...  problem271\n",
       "45095  N = int(input())\\nS = input()\\nanswer = []\\nfo...  problem271\n",
       "45096  n = int(input())\\nS = input()\\na = ord('A')\\nz...  problem271\n",
       "45097  alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\\nn = i...  problem271\n",
       "45098  N = int(input())\\nS = input()\\nres = ''\\nfor c...  problem271\n",
       "45099  import sys, bisect, math, itertools, string, q...  problem271\n",
       "45100  n = int(input())\\ns = input()\\nans = ''\\nfor i...  problem271"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/graphcodebert-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/fbcad0b46d9ae4a470863282512d88eccab1ea29ccb91d509cc1085d31fa045d.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c6821e0bb6c31686c5f329939756805a0fce4323f95fca8f6a3fb77e97ebf101.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/487c9a154b15188eb68625c719ac71e12840a7b0968805e842dcb5de1531fd39.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
      "loading file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/14c6f7696988761878b8b4981f8634ad5ff93e731bd23fb76ec27be7cbae1fdd.024cc07195c0ba0b51d4f80061c6115996ff26233f3d04788855b23cdf13fbd5\n",
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/graphcodebert-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/graphcodebert-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>160.123789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>500.930345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97566.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  45101.000000\n",
       "mean     160.123789\n",
       "std      500.930345\n",
       "min        5.000000\n",
       "25%       61.000000\n",
       "50%      108.000000\n",
       "75%      200.000000\n",
       "max    97566.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "df['tokens'] = df['code'].apply(tokenizer.tokenize)\n",
    "df['len'] = df['tokens'].apply(len)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>137.920842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.933475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  43647.000000\n",
       "mean     137.920842\n",
       "std      104.933475\n",
       "min        5.000000\n",
       "25%       60.000000\n",
       "50%      104.000000\n",
       "75%      187.000000\n",
       "max      512.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = df[df['len'] <= 512].reset_index(drop=True)\n",
    "ndf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>problem_num</th>\n",
       "      <th>tokens</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import numpy as np\\nH = int(input())\\nW = int(...</td>\n",
       "      <td>problem236</td>\n",
       "      <td>[import, Ġn, umpy, Ġas, Ġnp, Ċ, H, Ġ=, Ġint, (...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import sys\\nread=sys.stdin.read\\nh,w,n=map(int...</td>\n",
       "      <td>problem236</td>\n",
       "      <td>[import, Ġsys, Ċ, read, =, sys, ., std, in, .,...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x = int(input())\\ny = int(input())\\nz = int(in...</td>\n",
       "      <td>problem236</td>\n",
       "      <td>[x, Ġ=, Ġint, (, input, ()), Ċ, y, Ġ=, Ġint, (...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>import sys\\nimport math\\nimport itertools\\nimp...</td>\n",
       "      <td>problem236</td>\n",
       "      <td>[import, Ġsys, Ċ, import, Ġmath, Ċ, import, Ġi...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import sys\\ninput = sys.stdin.readline\\nsys.se...</td>\n",
       "      <td>problem236</td>\n",
       "      <td>[import, Ġsys, Ċ, input, Ġ=, Ġsys, ., std, in,...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code problem_num  \\\n",
       "0  import numpy as np\\nH = int(input())\\nW = int(...  problem236   \n",
       "1  import sys\\nread=sys.stdin.read\\nh,w,n=map(int...  problem236   \n",
       "2  x = int(input())\\ny = int(input())\\nz = int(in...  problem236   \n",
       "3  import sys\\nimport math\\nimport itertools\\nimp...  problem236   \n",
       "4  import sys\\ninput = sys.stdin.readline\\nsys.se...  problem236   \n",
       "\n",
       "                                              tokens  len  \n",
       "0  [import, Ġn, umpy, Ġas, Ġnp, Ċ, H, Ġ=, Ġint, (...   44  \n",
       "1  [import, Ġsys, Ċ, read, =, sys, ., std, in, .,...   49  \n",
       "2  [x, Ġ=, Ġint, (, input, ()), Ċ, y, Ġ=, Ġint, (...   58  \n",
       "3  [import, Ġsys, Ċ, import, Ġmath, Ċ, import, Ġi...  177  \n",
       "4  [import, Ġsys, Ċ, input, Ġ=, Ġsys, ., std, in,...  113  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df, train_label, valid_label = train_test_split(\n",
    "        ndf,\n",
    "        ndf['problem_num'],\n",
    "        random_state=42,\n",
    "        test_size=0.1,\n",
    "        stratify=ndf['problem_num'],\n",
    "    )\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고: https://dacon.io/competitions/official/235900/codeshare/4907?page=1&dtype=recent \n",
    "from rank_bm25 import BM25Okapi\n",
    "from itertools import combinations\n",
    "codes = train_df['code'].to_list()\n",
    "problems = train_df['problem_num'].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "total_positive_pairs = []\n",
    "total_negative_pairs = []\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = train_df[train_df['problem_num'] == problem]['code']\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(),2))\n",
    "\n",
    "    solution_codes_indices = solution_codes.index.to_list()\n",
    "    negative_pairs = []\n",
    "\n",
    "    first_tokenized_code = tokenizer.tokenize(positive_pairs[0][0])\n",
    "    negative_code_scores = bm25.get_scores(first_tokenized_code)\n",
    "    negative_code_ranking = negative_code_scores.argsort()[::-1] # 내림차순\n",
    "    ranking_idx = 0\n",
    "    \n",
    "    for solution_code in solution_codes:\n",
    "        negative_solutions = []\n",
    "        while len(negative_solutions) < len(positive_pairs) // len(solution_codes):\n",
    "            high_score_idx = negative_code_ranking[ranking_idx]\n",
    "            \n",
    "            if high_score_idx not in solution_codes_indices:\n",
    "                negative_solutions.append(train_df['code'].iloc[high_score_idx])\n",
    "            ranking_idx += 1\n",
    "\n",
    "        for negative_solution in negative_solutions:\n",
    "            negative_pairs.append((solution_code, negative_solution))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "\n",
    "pos_code1 = list(map(lambda x:x[0],total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x:x[1],total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x:x[0],total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x:x[1],total_negative_pairs))\n",
    "\n",
    "pos_label = [1]*len(pos_code1)\n",
    "neg_label = [0]*len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    'code1':total_code1,\n",
    "    'code2':total_code2,\n",
    "    'similar':total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pair_data.to_csv('train_data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(pair_data['similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:52<00:00,  5.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from itertools import combinations\n",
    "codes = valid_df['code'].to_list()\n",
    "problems = valid_df['problem_num'].unique().tolist()\n",
    "problems.sort()\n",
    "\n",
    "tokenized_corpus = [tokenizer.tokenize(code) for code in codes]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "total_positive_pairs = []\n",
    "total_negative_pairs = []\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    solution_codes = valid_df[valid_df['problem_num'] == problem]['code']\n",
    "    positive_pairs = list(combinations(solution_codes.to_list(),2))\n",
    "\n",
    "    solution_codes_indices = solution_codes.index.to_list()\n",
    "    negative_pairs = []\n",
    "\n",
    "    first_tokenized_code = tokenizer.tokenize(positive_pairs[0][0])\n",
    "    negative_code_scores = bm25.get_scores(first_tokenized_code)\n",
    "    negative_code_ranking = negative_code_scores.argsort()[::-1] # 내림차순\n",
    "    ranking_idx = 0\n",
    "    \n",
    "    for solution_code in solution_codes:\n",
    "        negative_solutions = []\n",
    "        while len(negative_solutions) < len(positive_pairs) // len(solution_codes):\n",
    "            high_score_idx = negative_code_ranking[ranking_idx]\n",
    "            \n",
    "            if high_score_idx not in solution_codes_indices:\n",
    "                negative_solutions.append(valid_df['code'].iloc[high_score_idx])\n",
    "            ranking_idx += 1\n",
    "\n",
    "        for negative_solution in negative_solutions:\n",
    "            negative_pairs.append((solution_code, negative_solution))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "\n",
    "pos_code1 = list(map(lambda x:x[0],total_positive_pairs))\n",
    "pos_code2 = list(map(lambda x:x[1],total_positive_pairs))\n",
    "\n",
    "neg_code1 = list(map(lambda x:x[0],total_negative_pairs))\n",
    "neg_code2 = list(map(lambda x:x[1],total_negative_pairs))\n",
    "\n",
    "pos_label = [1]*len(pos_code1)\n",
    "neg_label = [0]*len(neg_code1)\n",
    "\n",
    "pos_code1.extend(neg_code1)\n",
    "total_code1 = pos_code1\n",
    "pos_code2.extend(neg_code2)\n",
    "total_code2 = pos_code2\n",
    "pos_label.extend(neg_label)\n",
    "total_label = pos_label\n",
    "pair_data = pd.DataFrame(data={\n",
    "    'code1':total_code1,\n",
    "    'code2':total_code2,\n",
    "    'similar':total_label\n",
    "})\n",
    "pair_data = pair_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "pair_data.to_csv('valid_data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59731, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='similar', ylabel='count'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(pair_data['similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\") \n",
    "valid_data = pd.read_csv(\"valid_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import sys\\ndef popcount(x: int):\\n\\treturn bi...</td>\n",
       "      <td>def popcnt(n):\\n\\treturn bin(n).count(\"1\")\\nde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import sys\\nfrom sys import exit\\nfrom collect...</td>\n",
       "      <td>from collections import deque\\ndef main():\\n  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from _collections import deque\\nfrom _ast impo...</td>\n",
       "      <td>t1,t2=map(int,input().split())\\na1,a2=map(int,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N = int(input())\\nd = [0] * N\\nc = 0\\nb = True...</td>\n",
       "      <td>import sys\\nn=int(input())\\nd=[]\\ncnt=0\\nfor i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import sys\\nimport math\\nimport time\\nreadline...</td>\n",
       "      <td>import math\\nfrom functools import reduce\\nK =...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               code1  \\\n",
       "0  import sys\\ndef popcount(x: int):\\n\\treturn bi...   \n",
       "1  import sys\\nfrom sys import exit\\nfrom collect...   \n",
       "2  from _collections import deque\\nfrom _ast impo...   \n",
       "3  N = int(input())\\nd = [0] * N\\nc = 0\\nb = True...   \n",
       "4  import sys\\nimport math\\nimport time\\nreadline...   \n",
       "\n",
       "                                               code2  similar  \n",
       "0  def popcnt(n):\\n\\treturn bin(n).count(\"1\")\\nde...        1  \n",
       "1  from collections import deque\\ndef main():\\n  ...        0  \n",
       "2  t1,t2=map(int,input().split())\\na1,a2=map(int,...        1  \n",
       "3  import sys\\nn=int(input())\\nd=[]\\ncnt=0\\nfor i...        1  \n",
       "4  import math\\nfrom functools import reduce\\nK =...        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X,N=map(int,input().split())\\nP=set(map(int,in...</td>\n",
       "      <td>X,N = (int(x) for x in input().split())\\np = s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>import math\\nr = float(input())\\nprint('%.6f %...</td>\n",
       "      <td>def main(X, Y):\\n\\tfor n_crane in range(X + 1)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>import math\\nn,m,x = map(int,input().split())\\...</td>\n",
       "      <td>n, k = map(int, input().split())\\np = list(map...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h, w = list(map(int, input().split()))\\nmasu =...</td>\n",
       "      <td>a, b = map(int,input().split())\\nn = a*b\\nif a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>import sys\\nimport os\\ndef file_input():\\n\\tf ...</td>\n",
       "      <td>def cmb(n, r, p):\\n\\tif (r &lt; 0) or (n &lt; r):\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               code1  \\\n",
       "0  X,N=map(int,input().split())\\nP=set(map(int,in...   \n",
       "1  import math\\nr = float(input())\\nprint('%.6f %...   \n",
       "2  import math\\nn,m,x = map(int,input().split())\\...   \n",
       "3  h, w = list(map(int, input().split()))\\nmasu =...   \n",
       "4  import sys\\nimport os\\ndef file_input():\\n\\tf ...   \n",
       "\n",
       "                                               code2  similar  \n",
       "0  X,N = (int(x) for x in input().split())\\np = s...        1  \n",
       "1  def main(X, Y):\\n\\tfor n_crane in range(X + 1)...        0  \n",
       "2  n, k = map(int, input().split())\\np = list(map...        0  \n",
       "3  a, b = map(int,input().split())\\nn = a*b\\nif a...        1  \n",
       "4  def cmb(n, r, p):\\n\\tif (r < 0) or (n < r):\\n\\...        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5159810, 3), (59731, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, valid_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/graphcodebert-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "https://huggingface.co/microsoft/graphcodebert-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpw0206kh6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cea7dda14c440958d17bcd51f7cef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/microsoft/graphcodebert-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/790fa523a045ef75a0bb2c78f19ccb8531275871a4a2a88b524292725e0e65c8.459848ee0fb5942db5cb70ab4db4066013ff7b1f52071fc5e5792f691a813b6c\n",
      "creating metadata file for /root/.cache/huggingface/transformers/790fa523a045ef75a0bb2c78f19ccb8531275871a4a2a88b524292725e0e65c8.459848ee0fb5942db5cb70ab4db4066013ff7b1f52071fc5e5792f691a813b6c\n",
      "loading weights file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/790fa523a045ef75a0bb2c78f19ccb8531275871a4a2a88b524292725e0e65c8.459848ee0fb5942db5cb70ab4db4066013ff7b1f52071fc5e5792f691a813b6c\n",
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\") \n",
    "model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5159810/5159810 [1:42:43<00:00, 837.09it/s]  \n"
     ]
    }
   ],
   "source": [
    "c1 = train_data['code1'].values \n",
    "c2 = train_data['code2'].values \n",
    "similar = train_data['similar']\n",
    "\n",
    "N = train_data.shape[0] \n",
    "MAX_LEN = 512 \n",
    "\n",
    "input_ids = np.zeros((N, MAX_LEN),dtype=int)\n",
    "attention_masks = np.zeros((N, MAX_LEN),dtype=int)\n",
    "labels = np.zeros((N),dtype=int)\n",
    "\n",
    "for i in tqdm(range(N), position=0, leave=True): \n",
    "    try:\n",
    "        cur_c1 = c1[i] \n",
    "        cur_c2 = c2[i]\n",
    "        encoded_input = tokenizer(cur_c1, cur_c2, return_tensors='pt', max_length=512, padding='max_length', truncation=True) \n",
    "        input_ids[i,] = encoded_input['input_ids'] \n",
    "        attention_masks[i,] = encoded_input['attention_mask'] \n",
    "        labels[i] = similar[i] \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        pass\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<telegram.message.Message at 0x55b5d8503a88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import telegram\n",
    "tel_token = \"5059732158:AAE87TaReNbDKH3_Fy-CAYCUuIO2qiUyK2I\"\n",
    "chat_id = 1720119057 \n",
    "bot = telegram.Bot(token=tel_token)\n",
    "\n",
    "bot.sendMessage(chat_id=chat_id, text=\"train preprocessing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59731/59731 [01:09<00:00, 860.76it/s]\n"
     ]
    }
   ],
   "source": [
    "c1 = valid_data['code1'].values \n",
    "c2 = valid_data['code2'].values \n",
    "similar = valid_data['similar']\n",
    "\n",
    "N = valid_data.shape[0] \n",
    "MAX_LEN = 512 \n",
    "\n",
    "valid_input_ids = np.zeros((N, MAX_LEN),dtype=int)\n",
    "valid_attention_masks = np.zeros((N, MAX_LEN),dtype=int)\n",
    "valid_labels = np.zeros((N),dtype=int)\n",
    "\n",
    "for i in tqdm(range(N), position=0, leave=True): \n",
    "    try:\n",
    "        cur_c1 = c1[i] \n",
    "        cur_c2 = c2[i]\n",
    "        encoded_input = tokenizer(cur_c1, cur_c2, return_tensors='pt', max_length=512, padding='max_length', truncation=True) \n",
    "        valid_input_ids[i,] = encoded_input['input_ids'] \n",
    "        valid_attention_masks[i,] = encoded_input['attention_mask'] \n",
    "        valid_labels[i] = similar[i] \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        pass\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5159810, 512]),\n",
       " torch.Size([5159810, 512]),\n",
       " torch.Size([5159810]),\n",
       " torch.Size([59731, 512]),\n",
       " torch.Size([59731, 512]),\n",
       " torch.Size([59731]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(input_ids, dtype=int)\n",
    "attention_masks = torch.tensor(attention_masks, dtype=int)\n",
    "labels = torch.tensor(labels, dtype=int)\n",
    "\n",
    "valid_input_ids = torch.tensor(valid_input_ids, dtype=int)\n",
    "valid_attention_masks = torch.tensor(valid_attention_masks, dtype=int) \n",
    "valid_labels = torch.tensor(valid_labels, dtype=int)  \n",
    "\n",
    "input_ids.shape, attention_masks.shape, labels.shape, valid_input_ids.shape, valid_attention_masks.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_ids, 'train_input_ids.pt')\n",
    "torch.save(attention_masks, 'train_attention_masks.pt')\n",
    "torch.save(labels, \"train_labels.pt\") \n",
    "\n",
    "torch.save(valid_input_ids, \"valid_input_ids.pt\") \n",
    "torch.save(valid_attention_masks, \"valid_attention_masks.pt\") \n",
    "torch.save(valid_labels, \"valid_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.load('train_input_ids.pt') \n",
    "attention_masks = torch.load('train_attention_masks.pt') \n",
    "labels = torch.load('train_labels.pt') \n",
    "\n",
    "valid_input_ids = torch.load('valid_input_ids.pt') \n",
    "valid_attention_masks = torch.load('valid_attention_masks.pt') \n",
    "valid_labels = torch.load('valid_labels.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data = TensorDataset(input_ids, attention_masks, labels) \n",
    "train_sampler = RandomSampler(train_data) \n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) \n",
    "\n",
    "validation_data = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels) \n",
    "validation_sampler = SequentialSampler(validation_data) \n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8edef9fb59cf1f2670191d673b13a719a79361a2ae12cc806f942649b8b90db8.62db6c94b05689b7cb238a1a38840e19d1014fc755a9e328ab74a6c672db2d3d\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/graphcodebert-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/graphcodebert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/790fa523a045ef75a0bb2c78f19ccb8531275871a4a2a88b524292725e0e65c8.459848ee0fb5942db5cb70ab4db4066013ff7b1f52071fc5e5792f691a813b6c\n",
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\") \n",
    "model.cuda() \n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps) \n",
    "\n",
    "def flat_accuracy(preds, labels): \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten() \n",
    "    labels_flat = labels.flatten() \n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat) \n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "loss_f = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 10000it [2:43:57,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10,000  of  161,245.    Elapsed: 2:43:57.\n",
      "  current average loss = 0.09112094516304496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 20000it [5:28:12,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 20,000  of  161,245.    Elapsed: 5:28:13.\n",
      "  current average loss = 0.06711813350437587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 21274it [5:49:11,  1.01it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Iteration: 30000it [8:12:20,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 30,000  of  161,245.    Elapsed: 8:12:21.\n",
      "  current average loss = 0.055172500686507316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 50000it [13:40:44,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50,000  of  161,245.    Elapsed: 13:40:45.\n",
      "  current average loss = 0.04296189216297636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 54373it [14:52:42,  1.01it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Iteration: 60000it [16:25:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 60,000  of  161,245.    Elapsed: 16:25:28.\n",
      "  current average loss = 0.03911556286762922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 60000it [16:26:08,  1.01it/s]\n"
     ]
    },
    {
     "ename": "NetworkError",
     "evalue": "urllib3 HTTPError HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5059732158:AAE87TaReNbDKH3_Fy-CAYCUuIO2qiUyK2I/sendMessage (Caused by NewConnectionError('<telegram.vendor.ptb_urllib3.urllib3.connection.VerifiedHTTPSConnection object at 0x7f53bbb2c1d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    616\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \"\"\"\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPSConnectionPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <telegram.vendor.ptb_urllib3.urllib3.connection.VerifiedHTTPSConnection object at 0x7f53bbb2c1d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/utils/request.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_con_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0murllib3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                             **urlopen_kw)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 **response_kw)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    665\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 666\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/vendor/ptb_urllib3/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5059732158:AAE87TaReNbDKH3_Fy-CAYCUuIO2qiUyK2I/sendMessage (Caused by NewConnectionError('<telegram.vendor.ptb_urllib3.urllib3.connection.VerifiedHTTPSConnection object at 0x7f53bbb2c1d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNetworkError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-15e2391db20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  current average loss = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'  current average loss = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/bot.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRT\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0613\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Entering: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exiting: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/bot.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, chat_id, text, parse_mode, disable_web_page_preview, disable_notification, reply_to_message_id, reply_markup, timeout, api_kwargs, allow_sending_without_reply, entities, protect_content)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mapi_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mprotect_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotect_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         )\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/bot.py\u001b[0m in \u001b[0;36m_message\u001b[0;34m(self, endpoint, data, reply_to_message_id, disable_notification, reply_markup, allow_sending_without_reply, timeout, api_kwargs, protect_content)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'media'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/bot.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, endpoint, data, timeout, api_kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         return self.request.post(\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;34mf'{self.base_url}/{endpoint}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meffective_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         )\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/utils/request.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, timeout)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0murlopen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             )\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/telegram/utils/request.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# HTTPError must come last as its the base urllib3 exception class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# TODO: do something smart here; for now just raise NetworkError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'urllib3 HTTPError {error}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNetworkError\u001b[0m: urllib3 HTTPError HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot5059732158:AAE87TaReNbDKH3_Fy-CAYCUuIO2qiUyK2I/sendMessage (Caused by NewConnectionError('<telegram.vendor.ptb_urllib3.urllib3.connection.VerifiedHTTPSConnection object at 0x7f53bbb2c1d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracies = [], [] \n",
    "val_losses, val_accuracies = [], []\n",
    "model.zero_grad() \n",
    "for i in range(epochs): \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time() \n",
    "    train_loss, train_accuracy = 0, 0 \n",
    "    model.train() \n",
    "    for step, batch in tqdm(enumerate(train_dataloader), desc=\"Iteration\", smoothing=0.05): \n",
    "        if step % 10000 == 0 and not step == 0: \n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            print('  current average loss = {}'.format(train_loss / step)) \n",
    "            bot.sendMessage(chat_id=chat_id, text = '  current average loss = {}'.format(train_loss / step))\n",
    "       \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        outputs = model(b_input_ids, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1] \n",
    "        train_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.detach().cpu().numpy() \n",
    "        train_accuracy += flat_accuracy(logits, label_ids)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "    avg_train_loss = train_loss / len(train_dataloader)  \n",
    "    avg_train_accuracy = train_accuracy / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss) \n",
    "    train_accuracies.append(avg_train_accuracy) \n",
    "    print(\"  Average training loss: {0:.8f}\".format(avg_train_loss))\n",
    "    print(\"  Average training accuracy: {0:.8f}\".format(avg_train_accuracy))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Validating...\") \n",
    "    t0 = time.time() \n",
    "    model.eval() \n",
    "    val_loss, val_accuracy = 0, 0 \n",
    "    for step, batch in tqdm(enumerate(validation_dataloader), desc=\"Iteration\", smoothing=0.05):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch \n",
    "        with torch.no_grad():     \n",
    "            outputs = model(b_input_ids, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0] \n",
    "        logits = logits.detach().cpu() \n",
    "        label_ids = b_labels.detach().cpu() \n",
    "        val_loss += loss_f(logits, label_ids)\n",
    "        \n",
    "        logits = logits.numpy() \n",
    "        label_ids = label_ids.numpy() \n",
    "        val_accuracy += flat_accuracy(logits, label_ids) \n",
    "        \n",
    "    avg_val_accuracy = val_accuracy / len(validation_dataloader)  \n",
    "    avg_val_loss = val_loss / len(validation_dataloader) \n",
    "    val_accuracies.append(avg_val_accuracy)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(\"  Average validation loss: {0:.8f}\".format(avg_val_loss))\n",
    "    print(\"  Average validation accuracy: {0:.8f}\".format(avg_val_accuracy))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    bot.sendMessage(chat_id=chat_id, text=\"Epoch {} Done!\".format(i+1))   \n",
    "    bot.sendMessage(chat_id=chat_id, text=\"avg validation loss = {}\".format(avg_val_loss)) \n",
    "    bot.sendMessage(chat_id=chat_id, text=\"avg validation accuracy = {}%\".format(avg_val_accuracy)) \n",
    "    \n",
    "    if np.min(val_losses) == val_losses[-1]:\n",
    "        print(\"saving current best checkpoint\") \n",
    "        torch.save(model.state_dict(), \"graphcodebert-base.pt\") \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference \n",
    "checkpoint = torch.load(\"graphcodebert-base.pt\")\n",
    "test_model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\")  \n",
    "test_model.load_state_dict(checkpoint) \n",
    "test_model.cuda() \n",
    "test_model.eval() \n",
    "\n",
    "test_c1 = test['code1'].values \n",
    "test_c2 = test['code2'].values \n",
    "m = nn.Sigmoid() \n",
    "pred_classes = []\n",
    "for i in tqdm(range(len(test_c1))):\n",
    "    encoded_input = tokenizer(test_c1[i], test_c2[i], return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "    input_id = encoded_input['input_ids'][0]\n",
    "    attention_mask = encoded_input['attention_mask'][0]\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        output = model(**encoded_input)\n",
    "    logits = output['logits'] \n",
    "    probs = m(logits) \n",
    "    probs = probs.detach().cpu().numpy() \n",
    "    pred_class = np.argmax(probs, axis=1)[0]\n",
    "    pred_classes.append(pred_class)\n",
    "    \n",
    "    \n",
    "ss = pd.read_csv(\"sample_submission.csv\") \n",
    "ss['similar'] = pred_classes \n",
    "ss.to_csv(\"graphcodebert_finetuned.csv\",index=False)\n",
    "\n",
    "\n",
    "bot.sendMessage(chat_id = chat_id, text = \"Testing Done!\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
